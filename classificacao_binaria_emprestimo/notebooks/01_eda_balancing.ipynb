{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 614 entries, 0 to 613\n",
      "Data columns (total 13 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Loan_ID            614 non-null    object \n",
      " 1   Gender             601 non-null    object \n",
      " 2   Married            611 non-null    object \n",
      " 3   Dependents         599 non-null    object \n",
      " 4   Education          614 non-null    object \n",
      " 5   Self_Employed      582 non-null    object \n",
      " 6   ApplicantIncome    614 non-null    int64  \n",
      " 7   CoapplicantIncome  614 non-null    float64\n",
      " 8   LoanAmount         592 non-null    float64\n",
      " 9   Loan_Amount_Term   600 non-null    float64\n",
      " 10  Credit_History     564 non-null    float64\n",
      " 11  Property_Area      614 non-null    object \n",
      " 12  Loan_Status        614 non-null    object \n",
      "dtypes: float64(4), int64(1), object(8)\n",
      "memory usage: 62.5+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = '../data/loan.csv'\n",
    "loan_data = pd.read_csv(file_path)\n",
    "\n",
    "loan_data.info()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((491, 11), (123, 11), (491,), (123,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Separar o conjunto em variáveis preditoras e variável alvo\n",
    "X = loan_data.drop(columns=['Loan_ID', 'Loan_Status'])  # Removendo a variável alvo e identificador\n",
    "y = loan_data['Loan_Status']\n",
    "\n",
    "# Realizar o train_test_split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Verificar tamanhos dos conjuntos\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((246, 11), (62, 11), (246,), (62,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "# Concatenar os dados de treino para realizar o downsampling\n",
    "train_data = pd.concat([X_train, y_train], axis=1)\n",
    "\n",
    "# Separar as classes majoritária e minoritária\n",
    "majority_class = train_data[train_data['Loan_Status'] == 'Y']\n",
    "minority_class = train_data[train_data['Loan_Status'] == 'N']\n",
    "\n",
    "# Realizar o downsampling da classe majoritária\n",
    "majority_downsampled = resample(\n",
    "    majority_class,\n",
    "    replace=False,  # Não realizar substituição\n",
    "    n_samples=len(minority_class),  # Tornar ambas as classes balanceadas\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Combinar a classe minoritária com a classe majoritária reduzida\n",
    "balanced_train_data = pd.concat([majority_downsampled, minority_class])\n",
    "\n",
    "# Separar novamente em variáveis preditoras e alvo\n",
    "X_balanced = balanced_train_data.drop(columns=['Loan_Status'])\n",
    "y_balanced = balanced_train_data['Loan_Status']\n",
    "\n",
    "# Realizar novo train_test_split para treino e validação\n",
    "X_train_balanced, X_val, y_train_balanced, y_val = train_test_split(\n",
    "    X_balanced, y_balanced, test_size=0.2, random_state=42, stratify=y_balanced\n",
    ")\n",
    "\n",
    "# Verificar tamanhos dos conjuntos balanceados\n",
    "X_train_balanced.shape, X_val.shape, y_train_balanced.shape, y_val.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['Gender', 'Married', 'Dependents', 'Education', 'Self_Employed',\n",
       "        'ApplicantIncome', 'LoanAmount'],\n",
       "       dtype='object'),\n",
       " Index(['Gender', 'Married', 'Dependents', 'Education', 'Self_Employed',\n",
       "        'ApplicantIncome', 'LoanAmount'],\n",
       "       dtype='object'),\n",
       " Index(['Gender', 'Married', 'Dependents', 'Education', 'Self_Employed',\n",
       "        'ApplicantIncome', 'LoanAmount'],\n",
       "       dtype='object'))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remover as colunas especificadas nos conjuntos de treino, validação e teste\n",
    "columns_to_drop = ['Loan_ID', 'CoapplicantIncome', 'Loan_Amount_Term', 'Credit_History', 'Property_Area']\n",
    "\n",
    "X_train_balanced = X_train_balanced.drop(columns=columns_to_drop, errors='ignore')\n",
    "X_val = X_val.drop(columns=columns_to_drop, errors='ignore')\n",
    "X_test = X_test.drop(columns=columns_to_drop, errors='ignore')\n",
    "\n",
    "# Verificar a nova estrutura dos conjuntos\n",
    "X_train_balanced.columns, X_val.columns, X_test.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joel_\\AppData\\Local\\Temp\\ipykernel_9396\\834650332.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_train_balanced[col].fillna(most_frequent_value, inplace=True)\n",
      "C:\\Users\\joel_\\AppData\\Local\\Temp\\ipykernel_9396\\834650332.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_val[col].fillna(most_frequent_value, inplace=True)\n",
      "C:\\Users\\joel_\\AppData\\Local\\Temp\\ipykernel_9396\\834650332.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_test[col].fillna(most_frequent_value, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Gender              0\n",
       " Married             0\n",
       " Dependents          0\n",
       " Education           0\n",
       " Self_Employed       0\n",
       " ApplicantIncome     0\n",
       " LoanAmount         14\n",
       " dtype: int64,\n",
       " Gender             0\n",
       " Married            0\n",
       " Dependents         0\n",
       " Education          0\n",
       " Self_Employed      0\n",
       " ApplicantIncome    0\n",
       " LoanAmount         1\n",
       " dtype: int64,\n",
       " Gender             0\n",
       " Married            0\n",
       " Dependents         0\n",
       " Education          0\n",
       " Self_Employed      0\n",
       " ApplicantIncome    0\n",
       " LoanAmount         2\n",
       " dtype: int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preencher os valores ausentes com os valores majoritários de cada coluna\n",
    "columns_to_fill = ['Dependents', 'Self_Employed', 'Married', 'Gender']\n",
    "\n",
    "# Iterar sobre as colunas e preencher os valores ausentes\n",
    "for col in columns_to_fill:\n",
    "    most_frequent_value = X_train_balanced[col].mode()[0]\n",
    "    X_train_balanced[col].fillna(most_frequent_value, inplace=True)\n",
    "    X_val[col].fillna(most_frequent_value, inplace=True)\n",
    "    X_test[col].fillna(most_frequent_value, inplace=True)\n",
    "\n",
    "# Verificar se ainda há valores ausentes nos conjuntos de dados\n",
    "missing_values_train = X_train_balanced.isnull().sum()\n",
    "missing_values_val = X_val.isnull().sum()\n",
    "missing_values_test = X_test.isnull().sum()\n",
    "\n",
    "missing_values_train, missing_values_val, missing_values_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joel_\\AppData\\Local\\Temp\\ipykernel_9396\\538567937.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_train_balanced['LoanAmount'].fillna(mode_loan_amount, inplace=True)\n",
      "C:\\Users\\joel_\\AppData\\Local\\Temp\\ipykernel_9396\\538567937.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_val['LoanAmount'].fillna(mode_loan_amount, inplace=True)\n",
      "C:\\Users\\joel_\\AppData\\Local\\Temp\\ipykernel_9396\\538567937.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_test['LoanAmount'].fillna(mode_loan_amount, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Gender             0\n",
       " Married            0\n",
       " Dependents         0\n",
       " Education          0\n",
       " Self_Employed      0\n",
       " ApplicantIncome    0\n",
       " LoanAmount         0\n",
       " dtype: int64,\n",
       " Gender             0\n",
       " Married            0\n",
       " Dependents         0\n",
       " Education          0\n",
       " Self_Employed      0\n",
       " ApplicantIncome    0\n",
       " LoanAmount         0\n",
       " dtype: int64,\n",
       " Gender             0\n",
       " Married            0\n",
       " Dependents         0\n",
       " Education          0\n",
       " Self_Employed      0\n",
       " ApplicantIncome    0\n",
       " LoanAmount         0\n",
       " dtype: int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preencher os valores ausentes na coluna LoanAmount com o valor predominante (moda)\n",
    "mode_loan_amount = X_train_balanced['LoanAmount'].mode()[0]\n",
    "\n",
    "X_train_balanced['LoanAmount'].fillna(mode_loan_amount, inplace=True)\n",
    "X_val['LoanAmount'].fillna(mode_loan_amount, inplace=True)\n",
    "X_test['LoanAmount'].fillna(mode_loan_amount, inplace=True)\n",
    "\n",
    "# Verificar novamente se há valores ausentes nos conjuntos de dados\n",
    "missing_values_train = X_train_balanced.isnull().sum()\n",
    "missing_values_val = X_val.isnull().sum()\n",
    "missing_values_test = X_test.isnull().sum()\n",
    "\n",
    "missing_values_train, missing_values_val, missing_values_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(     Gender  Married Dependents  Education  Self_Employed  ApplicantIncome  \\\n",
       " 276       1        1          0          0              0             3993   \n",
       " 413       1        1          0          1              0             2253   \n",
       " 78        1        1         3+          0              0             3167   \n",
       " 441       1        1          0          0              0             7901   \n",
       " 218       1        1          2          0              0             5000   \n",
       " \n",
       "      LoanAmount  \n",
       " 276       207.0  \n",
       " 413       110.0  \n",
       " 78        180.0  \n",
       " 441       180.0  \n",
       " 218        72.0  ,\n",
       " array([1, 1, 0, 1, 0]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Instanciar o LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Listar as colunas categóricas a serem transformadas\n",
    "categorical_columns = ['Gender', 'Married', 'Education', 'Self_Employed']\n",
    "target_column = 'Loan_Status'\n",
    "\n",
    "# Aplicar o LabelEncoder nas colunas categóricas do conjunto de treino, validação e teste\n",
    "for col in categorical_columns:\n",
    "    X_train_balanced[col] = label_encoder.fit_transform(X_train_balanced[col])\n",
    "    X_val[col] = label_encoder.transform(X_val[col])\n",
    "    X_test[col] = label_encoder.transform(X_test[col])\n",
    "\n",
    "# Aplicar o LabelEncoder na variável alvo\n",
    "y_train_balanced = label_encoder.fit_transform(y_train_balanced)\n",
    "y_val = label_encoder.transform(y_val)\n",
    "y_test = label_encoder.transform(y_test)\n",
    "\n",
    "# Verificar as primeiras linhas para confirmar a transformação\n",
    "X_train_balanced.head(), y_train_balanced[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 3, 2, 1]), array([0, 1, 3, 2]), array([0, 1, 3, 2]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ajustar a coluna Dependents para que o valor '3+' seja substituído por 3\n",
    "X_train_balanced['Dependents'] = X_train_balanced['Dependents'].replace('3+', 3).astype(int)\n",
    "X_val['Dependents'] = X_val['Dependents'].replace('3+', 3).astype(int)\n",
    "X_test['Dependents'] = X_test['Dependents'].replace('3+', 3).astype(int)\n",
    "\n",
    "# Verificar os valores únicos para garantir que a transformação foi realizada corretamente\n",
    "unique_dependents_train = X_train_balanced['Dependents'].unique()\n",
    "unique_dependents_val = X_val['Dependents'].unique()\n",
    "unique_dependents_test = X_test['Dependents'].unique()\n",
    "\n",
    "unique_dependents_train, unique_dependents_val, unique_dependents_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Education</th>\n",
       "      <th>Self_Employed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.780256</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.272211</td>\n",
       "      <td>0.690484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.780256</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.514970</td>\n",
       "      <td>-0.474085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.218852</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.387451</td>\n",
       "      <td>0.366325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.780256</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.273020</td>\n",
       "      <td>0.366325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.219150</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.131718</td>\n",
       "      <td>-0.930308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Gender  Married  Dependents  Education  Self_Employed  ApplicantIncome  \\\n",
       "276       1        1   -0.780256          0              0        -0.272211   \n",
       "413       1        1   -0.780256          1              0        -0.514970   \n",
       "78        1        1    2.218852          0              0        -0.387451   \n",
       "441       1        1   -0.780256          0              0         0.273020   \n",
       "218       1        1    1.219150          0              0        -0.131718   \n",
       "\n",
       "     LoanAmount  \n",
       "276    0.690484  \n",
       "413   -0.474085  \n",
       "78     0.366325  \n",
       "441    0.366325  \n",
       "218   -0.930308  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Instanciar o StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Selecionar as colunas numéricas\n",
    "numeric_columns = ['ApplicantIncome', 'LoanAmount', 'Dependents']\n",
    "\n",
    "# Aplicar a padronização nos conjuntos de treino, validação e teste\n",
    "X_train_balanced[numeric_columns] = scaler.fit_transform(X_train_balanced[numeric_columns])\n",
    "X_val[numeric_columns] = scaler.transform(X_val[numeric_columns])\n",
    "X_test[numeric_columns] = scaler.transform(X_test[numeric_columns])\n",
    "\n",
    "# Verificar as primeiras linhas para confirmar a padronização\n",
    "X_train_balanced.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treinando Logistic Regression...\n",
      "Treinando Random Forest...\n",
      "Treinando SVM...\n",
      "Treinando KNN...\n",
      "Treinando Gradient Boosting...\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_predict\n",
    "from sklearn.metrics import classification_report, roc_auc_score, roc_curve\n",
    "\n",
    "# Definir os classificadores\n",
    "classifiers = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"SVM\": SVC(probability=True),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "}\n",
    "\n",
    "# Definir os parâmetros para GridSearch\n",
    "param_grids = {\n",
    "    \"Logistic Regression\": {'classifier__C': [0.1, 1, 10]},\n",
    "    \"Random Forest\": {'classifier__n_estimators': [50, 100], 'classifier__max_depth': [None, 10]},\n",
    "    \"SVM\": {'classifier__C': [0.1, 1, 10], 'classifier__kernel': ['linear', 'rbf']},\n",
    "    \"KNN\": {'classifier__n_neighbors': [3, 5, 7]},\n",
    "    \"Gradient Boosting\": {'classifier__n_estimators': [50, 100], 'classifier__learning_rate': [0.01, 0.1]},\n",
    "}\n",
    "\n",
    "# Preparar resultados\n",
    "results = {}\n",
    "\n",
    "# Executar cada classificador com Grid Search e validação cruzada\n",
    "for name, clf in classifiers.items():\n",
    "    print(f\"Treinando {name}...\")\n",
    "    pipeline = Pipeline([('classifier', clf)])\n",
    "    grid_search = GridSearchCV(pipeline, param_grids[name], cv=5, scoring='roc_auc', verbose=0)\n",
    "    grid_search.fit(X_train_balanced, y_train_balanced)\n",
    "    \n",
    "    # Obter melhores predições e métricas\n",
    "    best_model = grid_search.best_estimator_\n",
    "    y_pred = cross_val_predict(best_model, X_val, y_val, cv=5, method=\"predict\")\n",
    "    y_proba = cross_val_predict(best_model, X_val, y_val, cv=5, method=\"predict_proba\")[:, 1]\n",
    "    \n",
    "    # Classification report\n",
    "    report = classification_report(y_val, y_pred, output_dict=True)\n",
    "    \n",
    "    # AUC\n",
    "    auc_score = roc_auc_score(y_val, y_proba)\n",
    "    \n",
    "    # Guardar resultados\n",
    "    results[name] = {\n",
    "        \"Best Params\": grid_search.best_params_,\n",
    "        \"Classification Report\": report,\n",
    "        \"AUC\": auc_score,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          AUC  Precision    Recall  F1-Score\n",
      "Logistic Regression  0.625390   0.636364  0.677419  0.656250\n",
      "Random Forest        0.480749   0.566667  0.548387  0.557377\n",
      "SVM                  0.380853   0.541667  0.838710  0.658228\n",
      "KNN                  0.469823   0.451613  0.451613  0.451613\n",
      "Gradient Boosting    0.452133   0.466667  0.451613  0.459016\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Dicionário para armazenar as métricas\n",
    "metrics_results = {}\n",
    "\n",
    "# Para cada modelo, calcular as métricas\n",
    "for name, clf in classifiers.items():\n",
    "    # Treinar o modelo no conjunto balanceado\n",
    "    pipeline = Pipeline([('classifier', clf)])\n",
    "    grid_search = GridSearchCV(pipeline, param_grids[name], cv=5, scoring='roc_auc', verbose=0)\n",
    "    grid_search.fit(X_train_balanced, y_train_balanced)\n",
    "    \n",
    "    # Previsões no conjunto de validação\n",
    "    y_pred = grid_search.best_estimator_.predict(X_val)\n",
    "    \n",
    "    # Calcular as métricas\n",
    "    precision = precision_score(y_val, y_pred)\n",
    "    recall = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "    auc_score = roc_auc_score(y_val, grid_search.best_estimator_.predict_proba(X_val)[:, 1])\n",
    "    \n",
    "    # Armazenar os resultados\n",
    "    metrics_results[name] = {\n",
    "        \"AUC\": auc_score,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"F1-Score\": f1\n",
    "    }\n",
    "\n",
    "# Apresentar as métricas em formato de DataFrame\n",
    "import pandas as pd\n",
    "metrics_df = pd.DataFrame(metrics_results).T\n",
    "\n",
    "# Exibir as métricas\n",
    "print(metrics_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline salvo em: ../data/final_logistic_regression_pipeline.pkl\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Configurar e treinar o modelo Logistic Regression\n",
    "final_model = LogisticRegression(C=1)  # Ajuste o valor de C para o encontrado na validação\n",
    "final_pipeline = Pipeline([('classifier', final_model)])\n",
    "\n",
    "# Treinar o pipeline com os dados de treino balanceados\n",
    "final_pipeline.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Salvar o pipeline final\n",
    "output_path = '../data/final_logistic_regression_pipeline.pkl'\n",
    "joblib.dump(final_pipeline, output_path)\n",
    "\n",
    "print(f\"Pipeline salvo em: {output_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
